{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Leveraging Softmax Attention as a Replacement for Cosine Similarity in High-Dimensional Embedding Retrieval Systems (título fantasia)\n",
        "\n",
        "<details>\n",
        "<summary> <strong> Títulos possíveis </strong> </summary>\n",
        "\n",
        "- An Attention-Driven Approach to Optimizing Embedding Retrieval in Vector Databases: A Softmax-Based Query-Key Mechanism for Enhanced Semantic Search\n",
        "- Information Retrieval in High-Dimensional Vector Spaces: Leveraging Attention Mechanisms for Optimized Query-Embedding Projections\n",
        "- Augmenting Vector Database Search via Scaled Dot-Product Attention: A Reformulation of Cosine Similarity in Hyperplane Embedding Spaces\n",
        "- Softmax-Driven Query-Key Attention Models for Enhanced Similarity Matching in N-Dimensional Vectorial Manifolds\n",
        "- Reformulating Similarity Search in Vector Databases: A Deep Dive into Attention-Driven Query Optimization\n",
        "- Scaling Embedding-Based Information Retrieval with Attention Mechanisms: A Computational Approach to Vector Space Search\n",
        "- Softmax Attention as a Replacement for Cosine Similarity in High-Dimensional Embedding Retrieval Systems\n",
        "- Rearchitecting Vector Database Queries: Leveraging Attention Models for Enhanced Information Retrieval and Efficiency\n",
        "- Optimizing Query Retrieval in Vector Databases: A Computational Model for Attention-Based Embedding Matching\n",
        "\n",
        "</details>\n",
        "\n",
        "GPT Description:\n",
        "\n",
        "In this paper, we propose a novel method for optimizing information retrieval from vector databases using attention mechanisms, replacing traditional cosine similarity-based approaches. Our focus is on improving the efficiency and accuracy of query matching in large-scale embedding spaces, particularly in the context of retrieval-augmented generation (RAG) systems, where embeddings play a pivotal role in linking queries to relevant documents or knowledge units. By integrating a scaled dot-product attention mechanism into the retrieval process, we enhance the capacity of the system to prioritize more semantically relevant embeddings during search operations. This approach redefines the way queries interact with embeddings in a vector space, treating the retrieval task as an attention-based alignment problem. The attention mechanism dynamically weighs the importance of different dimensions in the query and embedding representations, ultimately improving the precision of retrieved results."
      ],
      "metadata": {
        "id": "dW22YhPCROG9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## To-do\n",
        "Implementação em código / design de experimento\n",
        "- [X] Implementar o attention (scaled dot-product attention mechanism)\n",
        "- [X] Otimizar o mecanismo de atenção\n",
        "- [X] Implementar o vetorial DB (att-based)\n",
        "- [X] Vector DB com similaridade de cosseno para comparação\n",
        "- [X] Vector DB com distância euclidiana para comparação\n",
        "- [X] Vector DB com distância Manhattan para comparação\n",
        "- [ ] Implementar [Multidimensional Comparisons: Dimension Insensitive Euclidean Metric](https://arxiv.org/pdf/2407.08623) (novo algoritmo que propõe uma substituição de  similaridade de cosseno)\n",
        "- [ ] Replicar os testes do paper do DIEM, porém utilizando attention\n",
        "- [ ] Organizar um benchmarking com vários datasets e desempenhar Needle in a Haystack em vários tamanhos (4k, 8k, 16k,..., 1000k) - padronizar as queries em todas as métricas de avaliação\n",
        "- [ ] Rodar todos os modelos pelo menos 2000x para avaliar os resultados e tirar medidas de variação (std deviation e etc)\n",
        "- [ ] Definir as métrica de avaliação para o retrieval\n",
        "\n",
        "Benchmark e avaliação\n",
        "- [Open Compass benchmarking](https://opencompass.readthedocs.io/en/latest/advanced_guides/needleinahaystack_eval.html)\n",
        "\n",
        "Possíveis perguntas de pesquisa\n",
        "- How can attention mechanisms improve the precision and recall of retrieval systems compared to traditional cosine similarity in high-dimensional embedding spaces?\n",
        "- What are the computational trade-offs between using attention-based mechanisms and cosine similarity for large-scale vector database searches?\n",
        "- How does using attention mechanisms impact the semantic alignment between query vectors and document embeddings compared to static similarity measures like cosine similarity?\n",
        "- In what scenarios do attention-based retrieval mechanisms outperform cosine similarity in terms of context-sensitive search results?\n",
        "- Can attention-based retrieval methods dynamically adjust the relevance of embeddings to better reflect changing contextual priorities in real-time search queries?\n",
        "- What are the effects of integrating attention-based mechanisms with traditional vector search systems in terms of speed, accuracy, and flexibility?\n",
        "- Can attention-based models effectively bridge the gap between query embeddings and document embeddings in low-resource or multilingual contexts where cosine similarity struggles?\n",
        "\n"
      ],
      "metadata": {
        "id": "QlaDebWv8Fxf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setup\n",
        "- Instalação de pacotes\n",
        "- Imports\n",
        "- Definição dos modelos-base de avaliação\n",
        "- Definição do nano-dataset de teste para validar a ideia"
      ],
      "metadata": {
        "id": "lOXbEDOdR1-j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!pip install optuna\n",
        "!pip install \"opencompass[full]\""
      ],
      "metadata": {
        "id": "hSpSk_NmBP2F"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "cAL98hivRHsi"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import time\n",
        "import random\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "import optuna as opt\n",
        "import opencompass as oc\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import transformers\n",
        "from transformers import BertModel, BertTokenizer"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "# Definindo o modelo utilizado\n",
        "model_name = 'bert-base-uncased'\n",
        "model = BertModel.from_pretrained(model_name)\n",
        "tokenizer = BertTokenizer.from_pretrained(model_name)"
      ],
      "metadata": {
        "id": "WmyMJ_v1N8_c"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example sentences (use real embeddings in your use case)\n",
        "sentences = [\n",
        "    \"The First Industrial Revolution began in Britain in the late 18th century.\",\n",
        "    \"The invention of the steam engine was a key development during the First Industrial Revolution.\",\n",
        "    \"Factories and mechanized production transformed industries like textiles and iron.\",\n",
        "    \"The First Industrial Revolution marked a shift from manual labor to machine-based manufacturing.\",\n",
        "    \"Railways expanded rapidly during the First Industrial Revolution, connecting distant regions.\",\n",
        "    \"Steam power was used to run factories, locomotives, and ships, accelerating global trade.\",\n",
        "    \"The Industrial Revolution had a profound impact on urbanization and the growth of cities.\",\n",
        "    \"New inventions like the spinning jenny and the power loom revolutionized textile production.\",\n",
        "    \"Child labor and poor working conditions were common in early industrial factories.\",\n",
        "    \"The First Industrial Revolution laid the foundation for modern economies and industrial practices.\",\n",
        "    \"Bananananananananananananodnsaubdyiqwofnquohr. What were the main inventions during the First Industrial Revolution?\",\n",
        "    \"What were the main inventions during the First Industrial Revolution?\",\n",
        "    \"Pizza barbecue paella\"\n",
        "]\n",
        "\n",
        "query_sentence = \"What were the main inventions during the First Industrial Revolution?\" # Defining a query sentence"
      ],
      "metadata": {
        "id": "BS2L3T5eTwxY"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Base functions"
      ],
      "metadata": {
        "id": "LFZRWXnZAh7p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to get BERT embedding for a sentence\n",
        "def get_embedding(text, model, tokenizer):\n",
        "    with torch.no_grad():\n",
        "        inputs = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True)\n",
        "        outputs = model(**inputs)\n",
        "        embedding = outputs.last_hidden_state[:, 0, :]  # Use CLS token's embedding\n",
        "    return embedding"
      ],
      "metadata": {
        "id": "J_XiA_80AkhO"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def training(model, X, y, epochs):\n",
        "    criterion = nn.Adam()  # You could use other losses like contrastive or triplet loss\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=0.0017)\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        output, _ = model(X)\n",
        "        loss = criterion(output, y)  # Compare model output to target labels\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if (epoch+1) % 10 == 0:\n",
        "            print(f'Epoch [{epoch+1}/{epochs}], Loss: {loss.item():.4f}')"
      ],
      "metadata": {
        "id": "gqQuzax7BkJT"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Cosine DB\n",
        "\n",
        "$ \\cos({θ}) = \\frac{|a^T . b|}{||a||.||b||}$\n",
        "\n",
        "## ⚠️ Corrigir para usar o tokenizer do BERT\n",
        "\n",
        "> Implementação retirada de [Building a Vector Database from Scratch in Python](https://medium.com/@vidiptvashist/building-a-vector-database-from-scratch-in-python-6bd683ba5171) por Vidipt Vashist\n"
      ],
      "metadata": {
        "id": "rrKYG0uTy9qv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# VectorStore class to store BERT embeddings\n",
        "class VectorStore_CS:\n",
        "    def __init__(self):\n",
        "        self.vector_data = {}  # A dictionary to store vectors\n",
        "\n",
        "    def add_vector(self, vector_id, vector):\n",
        "        \"\"\"\n",
        "        Add a vector to the store.\n",
        "        Args:\n",
        "            vector_id (str or int): A unique identifier for the vector.\n",
        "            vector (numpy.ndarray): The vector data to be stored.\n",
        "        \"\"\"\n",
        "        self.vector_data[vector_id] = vector\n",
        "\n",
        "    def find_similar_vectors(self, query_vector, num_results=5):\n",
        "        \"\"\"\n",
        "        Find similar vectors to the query vector using brute-force cosine similarity.\n",
        "        Args:\n",
        "            query_vector (numpy.ndarray): The query vector for similarity search.\n",
        "            num_results (int): The number of similar vectors to return.\n",
        "        Returns:\n",
        "            list: A list of (vector_id, similarity_score) tuples for the most similar vectors.\n",
        "        \"\"\"\n",
        "        query_vector = np.squeeze(query_vector)  # Remove extra dimensions\n",
        "        results = []\n",
        "\n",
        "        for vector_id, vector in self.vector_data.items():\n",
        "            vector = np.squeeze(vector)  # Remove extra dimensions\n",
        "            similarity = np.dot(query_vector, vector) / (np.linalg.norm(query_vector) * np.linalg.norm(vector))\n",
        "            results.append((vector_id, similarity))\n",
        "\n",
        "        # Sort by similarity in descending order\n",
        "        results.sort(key=lambda x: x[1], reverse=True)\n",
        "\n",
        "        # Return the top N results\n",
        "        return results[:num_results]\n"
      ],
      "metadata": {
        "id": "mIIJB9XX8OY9"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Establish a VectorStore instance\n",
        "vector_store = VectorStore_CS()\n",
        "\n",
        "# Generate and store BERT embeddings in VectorStore\n",
        "for sentence in sentences:\n",
        "    embedding = get_embedding(sentence, model, tokenizer)\n",
        "    vector_store.add_vector(sentence, embedding)\n",
        "\n",
        "# Generate BERT embedding for the query sentence\n",
        "query_vector = get_embedding(query_sentence, model, tokenizer)\n",
        "\n",
        "# Find similar sentences using BERT embeddings\n",
        "similar_sentences = vector_store.find_similar_vectors(query_vector, num_results=12)\n",
        "\n",
        "# Display similar sentences\n",
        "print(\"Query Sentence:\", query_sentence)\n",
        "print(\"Similar Sentences:\")\n",
        "\n",
        "for sentence, similarity in similar_sentences:\n",
        "    print(f\"{sentence}: Similarity = {similarity:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TRYEnZKYNgVd",
        "outputId": "c71dd6de-6bf2-4ddf-d50e-5c7dbdee5b32"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query Sentence: What were the main inventions during the First Industrial Revolution?\n",
            "Similar Sentences:\n",
            "What were the main inventions during the First Industrial Revolution?: Similarity = 1.0000\n",
            "Bananananananananananananodnsaubdyiqwofnquohr. What were the main inventions during the First Industrial Revolution?: Similarity = 0.9137\n",
            "The First Industrial Revolution laid the foundation for modern economies and industrial practices.: Similarity = 0.8561\n",
            "The invention of the steam engine was a key development during the First Industrial Revolution.: Similarity = 0.8474\n",
            "Child labor and poor working conditions were common in early industrial factories.: Similarity = 0.8322\n",
            "Pizza barbecue paella: Similarity = 0.8299\n",
            "The First Industrial Revolution marked a shift from manual labor to machine-based manufacturing.: Similarity = 0.8276\n",
            "The First Industrial Revolution began in Britain in the late 18th century.: Similarity = 0.7919\n",
            "The Industrial Revolution had a profound impact on urbanization and the growth of cities.: Similarity = 0.7865\n",
            "New inventions like the spinning jenny and the power loom revolutionized textile production.: Similarity = 0.7850\n",
            "Steam power was used to run factories, locomotives, and ships, accelerating global trade.: Similarity = 0.7686\n",
            "Railways expanded rapidly during the First Industrial Revolution, connecting distant regions.: Similarity = 0.7323\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Euclidian DB\n",
        "\n",
        "$ d(x,y) = \\sqrt{\\sum_{k=1}^{n}(x_k - y_k)^2} $"
      ],
      "metadata": {
        "id": "YEJsBp4BORle"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class VectorStore_Euc:\n",
        "    def __init__(self):\n",
        "        self.vector_data = {}\n",
        "\n",
        "    def add_vector(self, vector_id, vector):\n",
        "        self.vector_data[vector_id] = vector\n",
        "\n",
        "    def find_similar_vectors(self, query_vector, num_results: int):\n",
        "      query_vector = np.squeeze(query_vector)  # Remove extra dimensions\n",
        "      results = []\n",
        "\n",
        "      for vector_id, vector in self.vector_data.items():\n",
        "          vector = np.squeeze(vector)  # Remove extra dimensions\n",
        "          euclidian = np.linalg.norm(query_vector - vector)\n",
        "          results.append((vector_id, euclidian))\n",
        "\n",
        "      # Sort by similarity in ascending order\n",
        "      results.sort(key=lambda x: x[1], reverse=False)\n",
        "\n",
        "      # Return the top N results\n",
        "      return results[:num_results]"
      ],
      "metadata": {
        "id": "xGUz7TfkOVpx"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Establish a VectorStore instance\n",
        "vector_store_Euc = VectorStore_Euc()\n",
        "\n",
        "# Generate and store BERT embeddings in VectorStore\n",
        "for sentence in sentences:\n",
        "    embedding = get_embedding(sentence, model, tokenizer)\n",
        "    vector_store_Euc.add_vector(sentence, embedding)\n",
        "\n",
        "# Generate BERT embedding for the query sentence\n",
        "query_vector = get_embedding(query_sentence, model, tokenizer)\n",
        "\n",
        "# Find similar sentences using BERT embeddings\n",
        "similar_sentences = vector_store_Euc.find_similar_vectors(query_vector, num_results=12)\n",
        "\n",
        "# Display similar sentences\n",
        "print(\"Query Sentence:\", query_sentence)\n",
        "print(\"Similar Sentences:\")\n",
        "\n",
        "for sentence, similarity in similar_sentences:\n",
        "    print(f\"{sentence}: Similarity = {similarity:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P91fAEhxbUEa",
        "outputId": "114390c3-77a8-4853-c9d7-ec9f4c78ed44"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query Sentence: What were the main inventions during the First Industrial Revolution?\n",
            "Similar Sentences:\n",
            "What were the main inventions during the First Industrial Revolution?: Similarity = 0.0000\n",
            "Bananananananananananananodnsaubdyiqwofnquohr. What were the main inventions during the First Industrial Revolution?: Similarity = 6.0866\n",
            "The First Industrial Revolution laid the foundation for modern economies and industrial practices.: Similarity = 8.2074\n",
            "The invention of the steam engine was a key development during the First Industrial Revolution.: Similarity = 8.3710\n",
            "Pizza barbecue paella: Similarity = 8.5552\n",
            "Child labor and poor working conditions were common in early industrial factories.: Similarity = 8.7006\n",
            "The First Industrial Revolution marked a shift from manual labor to machine-based manufacturing.: Similarity = 9.0159\n",
            "The First Industrial Revolution began in Britain in the late 18th century.: Similarity = 9.9155\n",
            "The Industrial Revolution had a profound impact on urbanization and the growth of cities.: Similarity = 10.0051\n",
            "New inventions like the spinning jenny and the power loom revolutionized textile production.: Similarity = 10.0549\n",
            "Steam power was used to run factories, locomotives, and ships, accelerating global trade.: Similarity = 10.2656\n",
            "Factories and mechanized production transformed industries like textiles and iron.: Similarity = 11.2195\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Manhattan DB (tá com algum bug)\n",
        "\n",
        "$ d(x,y) = \\sqrt{\\sum_{k=1}^{n}|x_k - y_k|} $"
      ],
      "metadata": {
        "id": "JlQq0-khCg2N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class VectorStore_Man:\n",
        "    def __init__(self):\n",
        "        self.vector_data = {}\n",
        "\n",
        "    def add_vector(self, vector_id, vector):\n",
        "        self.vector_data[vector_id] = vector\n",
        "\n",
        "    def find_similar_vectors(self, query_vector, num_results: int):\n",
        "      query_vector = np.squeeze(query_vector)  # Remove extra dimensions\n",
        "      results = []\n",
        "\n",
        "      for vector_id, vector in self.vector_data.items():\n",
        "          vector = np.squeeze(vector)  # Remove extra dimensions\n",
        "          manhattan = np.absolute(query_vector - vector)\n",
        "          results.append((vector_id, manhattan))\n",
        "\n",
        "      ## Sort by similarity in ascending order\n",
        "      results.sort(key=lambda x: x[1], reverse=False)\n",
        "\n",
        "      # Return the top N results\n",
        "      return results[:num_results]"
      ],
      "metadata": {
        "id": "N_tX9oivbvRp"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Establish a VectorStore instance\n",
        "vector_store_Man = VectorStore_Man()\n",
        "\n",
        "# Generate and store BERT embeddings in VectorStore\n",
        "for sentence in sentences:\n",
        "    embedding = get_embedding(sentence, model, tokenizer)\n",
        "    vector_store_Man.add_vector(sentence, embedding)\n",
        "\n",
        "\n",
        "# Generate BERT embedding for the query sentence\n",
        "query_vector = get_embedding(query_sentence, model, tokenizer)\n",
        "\n",
        "\n",
        "# Find similar sentences using BERT embeddings\n",
        "similar_sentences = vector_store_Man.find_similar_vectors(query_vector, 12)\n",
        "\n",
        "\n",
        "# Display similar sentences\n",
        "print(\"Query Sentence:\", query_sentence)\n",
        "print(\"Similar Sentences:\")\n",
        "\n",
        "for sentence, similarity in similar_sentences:\n",
        "    print(f\"{sentence}: Similarity = {similarity:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 332
        },
        "id": "o12i-GdDcbYp",
        "outputId": "2ca50eb9-1e5d-4ae0-834f-1b62eb2a5148"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "Boolean value of Tensor with more than one value is ambiguous",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-02675afe88f5>\u001b[0m in \u001b[0;36m<cell line: 15>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;31m# Find similar sentences using BERT embeddings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0msimilar_sentences\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvector_store_Man\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind_similar_vectors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery_vector\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m12\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-11-cb1636b8d297>\u001b[0m in \u001b[0;36mfind_similar_vectors\u001b[0;34m(self, query_vector, num_results)\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m       \u001b[0;31m## Sort by similarity in ascending order\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m       \u001b[0mresults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreverse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m       \u001b[0;31m# Return the top N results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Boolean value of Tensor with more than one value is ambiguous"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Attention DB\n",
        "$ Attention(Q,K,V) = softmax(\\frac{QK^T}{ \\sqrt{d_k}})V$\n"
      ],
      "metadata": {
        "id": "n0Gn_IAjBHhn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Scaled dot-product attention mechanism"
      ],
      "metadata": {
        "id": "ndkXfbyYF5vb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Attention Model Definition\n",
        "class AttentionModel(nn.Module):\n",
        "    def __init__(self, emb_dim):\n",
        "        super(AttentionModel, self).__init__()\n",
        "        self.W_Q = nn.Linear(emb_dim, emb_dim)\n",
        "        self.W_K = nn.Linear(emb_dim, emb_dim)\n",
        "        self.W_V = nn.Linear(emb_dim, emb_dim)\n",
        "        self.softmax = nn.Softmax(dim=-1)\n",
        "\n",
        "    def forward(self, query_embedding, sentence_embeddings):\n",
        "        Q = self.W_Q(query_embedding)\n",
        "        K = self.W_K(sentence_embeddings)\n",
        "        V = self.W_V(sentence_embeddings)\n",
        "\n",
        "        scores = torch.matmul(Q, K.transpose(-2, -1)) / torch.sqrt(torch.tensor(K.shape[-1], dtype=torch.float32))\n",
        "        attention_weights = self.softmax(scores)\n",
        "        output = torch.matmul(attention_weights, V)\n",
        "        return output, attention_weights"
      ],
      "metadata": {
        "id": "o8a8Wy0yF5Ti"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Query in Att Vector DB"
      ],
      "metadata": {
        "id": "EvqydASXJ3If"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to query vector DB using attention mechanism\n",
        "def query_vector_db(query, attention_model, vector_db, tokenizer, bert_model):\n",
        "    # Get the query embedding\n",
        "    query_embedding = get_embedding(query, bert_model, tokenizer)\n",
        "    query_embedding = query_embedding.float().unsqueeze(0)  # Add batch dimension and ensure it's float32\n",
        "\n",
        "    # Apply attention mechanism between query and stored embeddings\n",
        "    db_tensor = vector_db.float()  # Ensure embeddings are float32\n",
        "    output, attention_weights = attention_model(query_embedding, db_tensor)  # Pass both query and sentence embeddings\n",
        "\n",
        "    return output, attention_weights"
      ],
      "metadata": {
        "id": "Sgx7GR8SJ8t4"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to evaluate retrieval using attention mechanism\n",
        "def evaluate_retrieval(attention_model, query, vector_db, tokenizer, bert_model):\n",
        "    output, attention_weights = query_vector_db(query, attention_model, vector_db, tokenizer, bert_model)\n",
        "\n",
        "    # Cosine similarity for comparison\n",
        "    query_embedding = get_embedding(query, bert_model, tokenizer)\n",
        "    cosine_similarities = torch.cosine_similarity(query_embedding.float(), vector_db.float())\n",
        "\n",
        "    print(\"Attention-based Retrieval Output:\", output)\n",
        "    print(\"\\nCosine Similarities:\", cosine_similarities)\n"
      ],
      "metadata": {
        "id": "CJ9-S649D7pr"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Vector Store"
      ],
      "metadata": {
        "id": "RFAIxljAGbMQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# VectorStore class to store and retrieve embeddings\n",
        "class VectorStore_Att:\n",
        "    def __init__(self):\n",
        "        self.vector_data = {}\n",
        "\n",
        "    def add_vector(self, vector_id, vector):\n",
        "        self.vector_data[vector_id] = vector\n",
        "\n",
        "    def get_vectors(self):\n",
        "        return self.vector_data\n",
        "\n",
        "# Create a vector store and store sentence embeddings\n",
        "vector_store_att = VectorStore_Att()"
      ],
      "metadata": {
        "id": "uZDDshXrGdIP"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Retrieval Evaluation"
      ],
      "metadata": {
        "id": "qzbdYeRCKHhr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to evaluate and display retrieval\n",
        "def evaluate_retrieval(attention_model, query, vector_db, tokenizer, bert_model, sentences):\n",
        "    output, attention_weights = query_vector_db(query, attention_model, vector_db, tokenizer, bert_model)\n",
        "\n",
        "    # Cosine similarity for comparison\n",
        "    query_embedding = get_embedding(query, bert_model, tokenizer)\n",
        "    cosine_similarities = torch.cosine_similarity(query_embedding.float(), vector_db.float())\n",
        "\n",
        "    # Sort sentences by similarity score (Cosine Similarity)\n",
        "    sorted_indices = torch.argsort(cosine_similarities, descending=True)\n",
        "\n",
        "    print(f\"Query Sentence: {query}\\n\")\n",
        "    print(\"Similar Sentences:\")\n",
        "    for idx in sorted_indices:\n",
        "        sentence = sentences[idx]\n",
        "        similarity = cosine_similarities[idx].item()\n",
        "        print(f\"{sentence}: Similarity = {similarity:.4f}\")"
      ],
      "metadata": {
        "id": "zokFv3CyERVz"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate embeddings for each sentence\n",
        "embeddings = torch.cat([get_embedding(sentence, model, tokenizer) for sentence in sentences])\n",
        "\n",
        "# Initialize the Attention Model\n",
        "embed_dim = embeddings.shape[1]  # Dimensionality of BERT embeddings (768)\n",
        "attention_model = AttentionModel(embed_dim)\n",
        "\n",
        "evaluate_retrieval(attention_model, query_sentence, embeddings, tokenizer, model, sentences)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mQZW4BxNC1sz",
        "outputId": "185393d2-c09e-4d08-8b0f-586ccb98e223"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query Sentence: What were the main inventions during the First Industrial Revolution?\n",
            "\n",
            "Similar Sentences:\n",
            "What were the main inventions during the First Industrial Revolution?: Similarity = 1.0000\n",
            "Bananananananananananananodnsaubdyiqwofnquohr. What were the main inventions during the First Industrial Revolution?: Similarity = 0.9137\n",
            "The First Industrial Revolution laid the foundation for modern economies and industrial practices.: Similarity = 0.8561\n",
            "The invention of the steam engine was a key development during the First Industrial Revolution.: Similarity = 0.8474\n",
            "Child labor and poor working conditions were common in early industrial factories.: Similarity = 0.8322\n",
            "Pizza barbecue paella: Similarity = 0.8299\n",
            "The First Industrial Revolution marked a shift from manual labor to machine-based manufacturing.: Similarity = 0.8276\n",
            "The First Industrial Revolution began in Britain in the late 18th century.: Similarity = 0.7919\n",
            "The Industrial Revolution had a profound impact on urbanization and the growth of cities.: Similarity = 0.7865\n",
            "New inventions like the spinning jenny and the power loom revolutionized textile production.: Similarity = 0.7850\n",
            "Steam power was used to run factories, locomotives, and ships, accelerating global trade.: Similarity = 0.7686\n",
            "Railways expanded rapidly during the First Industrial Revolution, connecting distant regions.: Similarity = 0.7323\n",
            "Factories and mechanized production transformed industries like textiles and iron.: Similarity = 0.7193\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## DIEM DB\n",
        "\n",
        "$DIEM = \\frac{v_M - v_m}{\\sigma(n)^2} \\left( \\sqrt{\\sum_{i=1}^{n} (a_i - b_i)^2} - \\mathbb{E}[d(n)] \\right)$\n",
        "- ${v_M}$ é o valor máximo que os elementos no vetor podem assumir;\n",
        "- $v_m$ é o valor mínimo que os elementos do vetor podem assumir;\n",
        "- $\\sigma({n})^2$ é a variância da distância euclidiana para uma dada dimensão $n$;\n",
        "- $a_i$ e $b_i$ são os _i-ésimos_ elementos de $\\vec{a}$ e $\\vec{b}$, respectivamente;\n",
        "- $n$ é o número de dimensões nos vetores comparados;\n",
        "- $\\mathbb{E}[d(n)]$ é o valor esperado da distância euclidiana entre quaisquer dois vetores aleatórios $a, b \\sim U(vm, vM)$ para uma dada dimensão $n$.\n",
        "\n",
        "<!--\n",
        "Calculando $\\mathbb{E}[d(n)]$\n",
        "\n",
        "Dada a definição do limite superior do valor que $\\mathbb{E}[d(n)]$ pode assumir, definido pela desigualdade de Jensen e pela LOTUS (Law of the unconscious statistician), o limite superior de $\\mathbb{E}[d(n)]$ é dado por:\n",
        "\n",
        "$\\mathbb{E}[d(n)] \\leq \\sqrt{\\frac{n}{6}} \\times (v_M - v_m), ∀  n \\gt 2$, o limite superior é igual à mediana\n",
        "-->\n",
        "\n",
        "- $DIEM_{min} = \\frac{-v_M - v_m}{\\sigma(n)^2} \\mathbb{E}[d(n)]$\n",
        "\n",
        "- $DIEM_{max} = \\frac{v_M - v_n}{\\sigma(n)^2} \\sqrt{n} (v_M - v_m) - \\mathbb{E}[d(n)] $"
      ],
      "metadata": {
        "id": "poWqpKqQC2wx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Calculando o desvio padrão $\\sigma(n)$"
      ],
      "metadata": {
        "id": "XCL6LHATbMdy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def calcula_sigma_n(\n",
        "    n: int,\n",
        "    vM: float,\n",
        "    vm:float,\n",
        "    num_samples: int =10000): -> float\n",
        "\n",
        "    \"\"\"\n",
        "    Calcula o desvio padrão da distância euclidiana para a dimensão n\n",
        "    usando simulação.\n",
        "\n",
        "    Args:\n",
        "      n: Número de dimensões.\n",
        "      vM: Valor máximo dos elementos do vetor.\n",
        "      vm: Valor mínimo dos elementos do vetor.\n",
        "      num_samples: Número de amostras para a simulação (opcional).\n",
        "\n",
        "    Returns:\n",
        "      O desvio padrão da distância euclidiana para a dimensão n.\n",
        "    \"\"\"\n",
        "    vetores_a = np.random.uniform(vm, vM, size=(num_samples, n))\n",
        "    vetores_b = np.random.uniform(vm, vM, size=(num_samples, n))\n",
        "    distancias = np.linalg.norm(vetores_a - vetores_b, axis=1)\n",
        "    return np.std(distancias)"
      ],
      "metadata": {
        "id": "cUKBkP1oaoz1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Calculando $DIEM$"
      ],
      "metadata": {
        "id": "HTU-jfs2b_NQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def diem(\n",
        "    a: np.ndarray,\n",
        "    b: np.ndarray,\n",
        "    vM: float,\n",
        "    vm: float):\n",
        "    \"\"\"\n",
        "    Calcula o DIEM entre dois vetores a e b.\n",
        "\n",
        "    Args:\n",
        "      a: O primeiro vetor.\n",
        "      b: O segundo vetor.\n",
        "      vM: Valor máximo dos elementos do vetor.\n",
        "      vm: Valor mínimo dos elementos do vetor.\n",
        "\n",
        "    Returns:\n",
        "      O valor DIEM entre os vetores a e b.\n",
        "    \"\"\"\n",
        "    n = len(a)\n",
        "    sigma_n = calcula_sigma_n(n, vM, vm)\n",
        "    distancia_euclidiana = np.linalg.norm(a - b)\n",
        "    # Cálculo do DIEM usando a Equação 13 da\n",
        "    diem_value = (vM - vm) / (sigma_n ** 2) * (distancia_euclidiana - np.sqrt(n * ((vM - vm) ** 2) / 6))\n",
        "    return diem_value"
      ],
      "metadata": {
        "id": "HfYiJ0r6bAnO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class VectorStore_DIEM:\n",
        "    def __init__(self, vM, vm):\n",
        "        self.vector_data = {}\n",
        "        self.vM = vM\n",
        "        self.vm = vm\n",
        "\n",
        "    def add_vector(self, vector_id, vector):\n",
        "        \"\"\"Armazena um vetor na base de dados.\"\"\"\n",
        "        self.vector_data[vector_id] = vector\n",
        "\n",
        "    def find_similar_vectors(self, query_vector, num_results=5):\n",
        "        \"\"\"Encontra os vetores mais similares usando a métrica DIEM.\"\"\"\n",
        "        query_vector = np.squeeze(query_vector)\n",
        "\n",
        "        results = []\n",
        "        for vector_id, vector in self.vector_data.items():\n",
        "            vector = np.squeeze(vector)\n",
        "\n",
        "            # Usando DIEM para calcular a similaridade\n",
        "            similarity = diem(query_vector, vector, self.vM, self.vm)\n",
        "            results.append((vector_id, similarity))\n",
        "\n",
        "        # Ordenando por similaridade DIEM (menor distância = mais similar)\n",
        "        results.sort(key=lambda x: x[1])\n",
        "        return results[:num_results]"
      ],
      "metadata": {
        "id": "r6cCVB_T7DU5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the vector store with DIEM settings\n",
        "vector_store_DIEM = VectorStore_DIEM(vM=1.0, vm=0.0)\n",
        "\n",
        "# Assuming get_embedding function and BERT model are already defined\n",
        "# Generate and store BERT embeddings in VectorStore\n",
        "for sentence in sentences:\n",
        "    embedding = get_embedding(sentence, model, tokenizer)\n",
        "    vector_store_DIEM.add_vector(sentence, embedding)\n",
        "\n",
        "# Generate BERT embedding for the query sentence\n",
        "query_sentence = \"What were the main inventions during the First Industrial Revolution?\"\n",
        "query_vector = get_embedding(query_sentence, model, tokenizer)\n",
        "\n",
        "# Find similar sentences using BERT embeddings\n",
        "similar_sentences = vector_store_DIEM.find_similar_vectors(query_vector, num_results=12)\n",
        "\n",
        "# Display similar sentences\n",
        "print(\"Query Sentence:\", query_sentence)\n",
        "print(\"Similar Sentences:\")\n",
        "\n",
        "for sentence, similarity in similar_sentences:\n",
        "    print(f\"{sentence}: Similarity = {similarity:.4f}\")"
      ],
      "metadata": {
        "id": "44svCqc3bFAr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Global evaluator\n",
        "Implementando um sistema de avaliação global comum a todos os algoritmos para execução de Needle in a haystack e para isso, precisamos:\n",
        "\n",
        "- [ ] Refazer o banco vetorial, implementando um único banco global e executar os testes apenas modificando o mecanismo de busca;\n",
        "- [ ] Extrair os dados de consumo computacional durante a execução das buscas;\n",
        "- [ ] Definir os modelos que executaremos a busca;\n",
        "- [ ] Selecionar o dataset de Needle in a Haystack para utilizar;\n",
        "- [ ] Automaticamente coletar os dados relacionados à avaliação do desempenho do modelo;\n"
      ],
      "metadata": {
        "id": "XIZJBkNkQfgT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class VectorStore:\n",
        "  def __init__(self):\n"
      ],
      "metadata": {
        "id": "dImmIigYaZIW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Testing the OpenCompass"
      ],
      "metadata": {
        "id": "36WiyJz7_bXb"
      }
    }
  ]
}